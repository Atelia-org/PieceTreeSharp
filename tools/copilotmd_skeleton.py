#!/usr/bin/env python3
"""
copilotmd_skeleton.py - ä» .copilotmd æ–‡ä»¶æå–éª¨æ¶ç»“æ„

åŠŸèƒ½ï¼š
- è§£æ Copilot å¯¹è¯æ—¥å¿—æ–‡ä»¶
- è¯†åˆ« Tool ç»“æœå—å¹¶çœç•¥å…¶å…·ä½“å†…å®¹
- æˆªæ–­ Assistant å·¥å…·è°ƒç”¨ä¸­çš„é•¿å­—ç¬¦ä¸²å‚æ•°
- ä¿ç•™å¯¹è¯ç»“æ„ï¼Œä¾¿äºå¿«é€Ÿæµè§ˆ

Tool ç»“æœå—è¯†åˆ«è§„åˆ™ï¼š
- ä»¥ `ğŸ› ï¸ toolu_` å¼€å¤´çš„è¡Œæ˜¯ Tool è¿”å›ç»“æœçš„æ ‡è¯†
- ä¸ Assistant è°ƒç”¨æ ¼å¼ `ğŸ› ï¸ xxx (toolu_` åŒºåˆ†

ç”¨æ³•ï¼š
    python copilotmd_skeleton.py input.copilotmd [-o output.copilotmd] [--stats]
"""

import argparse
import json
import re
import sys
from pathlib import Path

# å­—ç¬¦ä¸²æˆªæ–­é…ç½®
STRING_TRUNCATE_THRESHOLD = 100  # è¶…è¿‡æ­¤é•¿åº¦çš„å­—ç¬¦ä¸²å°†è¢«æˆªæ–­
STRING_KEEP_HEAD = 40            # ä¿ç•™å¼€å¤´çš„å­—ç¬¦æ•°
STRING_KEEP_TAIL = 40            # ä¿ç•™ç»“å°¾çš„å­—ç¬¦æ•°


def truncate_string(s: str, stats: dict) -> str:
    """æˆªæ–­å•ä¸ªé•¿å­—ç¬¦ä¸²"""
    if len(s) > STRING_TRUNCATE_THRESHOLD:
        omitted = len(s) - STRING_KEEP_HEAD - STRING_KEEP_TAIL
        stats['strings_truncated'] = stats.get('strings_truncated', 0) + 1
        stats['chars_saved'] = stats.get('chars_saved', 0) + omitted
        return f"{s[:STRING_KEEP_HEAD]}... ({omitted} chars omitted) ...{s[-STRING_KEEP_TAIL:]}"
    return s


def truncate_long_strings(obj, stats: dict):
    """
    é€’å½’éå† JSON å¯¹è±¡ï¼Œæˆªæ–­é•¿å­—ç¬¦ä¸²
    
    Args:
        obj: JSON å¯¹è±¡ï¼ˆdict, list, æˆ–åŸºæœ¬ç±»å‹ï¼‰
        stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸ï¼Œç”¨äºè®°å½•æˆªæ–­æ¬¡æ•°
        
    Returns:
        å¤„ç†åçš„å¯¹è±¡
    """
    if isinstance(obj, dict):
        return {k: truncate_long_strings(v, stats) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [truncate_long_strings(item, stats) for item in obj]
    elif isinstance(obj, str):
        return truncate_string(obj, stats)
    else:
        return obj


def truncate_json_strings_regex(json_str: str, stats: dict) -> str:
    """
    ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç›´æ¥åœ¨ JSON å­—ç¬¦ä¸²ä¸­æˆªæ–­é•¿å­—ç¬¦ä¸²å€¼
    ç”¨äºå¤„ç†åŒ…å«æ§åˆ¶å­—ç¬¦çš„æ— æ•ˆ JSON
    """
    def replace_long_string(match):
        # match.group(1) æ˜¯é”®åï¼Œmatch.group(2) æ˜¯å€¼
        key = match.group(1)
        value = match.group(2)
        truncated = truncate_string(value, stats)
        # éœ€è¦è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦ä»¥ä¾¿é‡æ–°åµŒå…¥ JSON
        truncated = truncated.replace('\\', '\\\\').replace('"', '\\"')
        return f'"{key}": "{truncated}"'
    
    # åŒ¹é… "key": "value" æ¨¡å¼
    # å€¼å¯ä»¥åŒ…å«è½¬ä¹‰åºåˆ— (\\.) æˆ–éå¼•å·éåæ–œæ å­—ç¬¦
    pattern = r'"(\w+)":\s*"((?:[^"\\]|\\.)*)"'
    return re.sub(pattern, replace_long_string, json_str, flags=re.DOTALL)


def process_tool_call_json(json_str: str, stats: dict) -> str:
    """
    å¤„ç†å·¥å…·è°ƒç”¨çš„ JSON å‚æ•°ï¼Œæˆªæ–­é•¿å­—ç¬¦ä¸²
    
    Args:
        json_str: JSON å­—ç¬¦ä¸²
        stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        
    Returns:
        å¤„ç†åçš„ JSON å­—ç¬¦ä¸²ï¼ˆä¿æŒæ ¼å¼åŒ–ï¼‰
    """
    try:
        obj = json.loads(json_str)
        processed = truncate_long_strings(obj, stats)
        return json.dumps(processed, ensure_ascii=False, indent=2)
    except json.JSONDecodeError:
        # JSON è§£æå¤±è´¥ï¼ˆå¯èƒ½åŒ…å«æ§åˆ¶å­—ç¬¦ï¼‰ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç›´æ¥å¤„ç†
        return truncate_json_strings_regex(json_str, stats)


def is_tool_result_marker(line: str) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦æ˜¯ Tool ç»“æœå—çš„èµ·å§‹æ ‡è¯†è¡Œ
    
    Tool ç»“æœæ ¼å¼: ğŸ› ï¸ toolu_vrtx_xxx
    Assistant è°ƒç”¨æ ¼å¼: ğŸ› ï¸ read_file (toolu_vrtx_xxx) { ... }
    
    åŒºåˆ†æ–¹å¼ï¼šTool ç»“æœç›´æ¥ä»¥ `ğŸ› ï¸ toolu_` å¼€å¤´
    """
    stripped = line.strip()
    # åŒ¹é… Tool ç»“æœæ ‡è¯†ï¼šğŸ› ï¸ åç›´æ¥è·Ÿ toolu_
    return bool(re.match(r'^ğŸ› ï¸\s+toolu_', stripped))


def is_tool_call_start(line: str) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦æ˜¯ Assistant å·¥å…·è°ƒç”¨å—çš„èµ·å§‹è¡Œ
    
    æ ¼å¼: ğŸ› ï¸ tool_name (toolu_xxx) {
    """
    stripped = line.strip()
    return bool(re.match(r'^ğŸ› ï¸\s+\w+\s+\(toolu_', stripped))


def extract_skeleton(content: str) -> tuple[str, dict]:
    """
    ä» .copilotmd å†…å®¹ä¸­æå–éª¨æ¶ç»“æ„
    
    Args:
        content: åŸå§‹æ–‡ä»¶å†…å®¹
        
    Returns:
        tuple: (éª¨æ¶å†…å®¹, ç»Ÿè®¡ä¿¡æ¯å­—å…¸)
    """
    lines = content.splitlines(keepends=True)
    result_lines = []
    stats = {
        'original_lines': len(lines),
        'kept_lines': 0,
        'omitted_lines': 0,
        'tool_blocks_processed': 0,
        'metadata_tools_omitted': False
    }
    
    i = 0
    in_tool_result_block = False
    in_metadata_tools = False  # æ˜¯å¦åœ¨ Metadata çš„ tools åˆ—è¡¨ä¸­
    tools_bracket_depth = 0    # è·Ÿè¸ª tools åˆ—è¡¨çš„æ‹¬å·æ·±åº¦
    omitted_count = 0
    
    while i < len(lines):
        line = lines[i]
        
        # æ£€æµ‹ Metadata ä¸­çš„ tools åˆ—è¡¨å¼€å§‹
        if not in_metadata_tools and line.strip().startswith('tools') and ': [' in line:
            result_lines.append('tools            : [ ... tools list omitted ... ]\n')
            stats['kept_lines'] += 1
            in_metadata_tools = True
            tools_bracket_depth = 1  # è·Ÿè¸ªæ‹¬å·æ·±åº¦
            stats['metadata_tools_omitted'] = True
            i += 1
            continue
        
        # åœ¨ Metadata tools åˆ—è¡¨ä¸­ï¼Œé€šè¿‡æ‹¬å·åŒ¹é…æ‰¾ç»“æŸ
        if in_metadata_tools:
            # è®¡ç®—è¿™ä¸€è¡Œçš„æ‹¬å·å˜åŒ–
            tools_bracket_depth += line.count('[') - line.count(']')
            if tools_bracket_depth <= 0:
                in_metadata_tools = False
            stats['omitted_lines'] += 1
            i += 1
            continue
        
        if in_tool_result_block:
            # åœ¨ Tool ç»“æœå—å†…éƒ¨ï¼ŒæŸ¥æ‰¾ä»£ç å—ç»“æŸæ ‡è®°
            if line.strip() == '~~~':
                # æ‰¾åˆ°ç»“æŸæ ‡è®°ï¼Œæ’å…¥çœç•¥æç¤ºå¹¶ä¿ç•™ç»“æŸæ ‡è®°
                if omitted_count > 0:
                    result_lines.append(f'... ({omitted_count} lines omitted)\n')
                    stats['kept_lines'] += 1
                result_lines.append(line)
                stats['kept_lines'] += 1
                in_tool_result_block = False
                omitted_count = 0
            else:
                # è·³è¿‡å†…å®¹è¡Œ
                stats['omitted_lines'] += 1
                omitted_count += 1
        elif is_tool_result_marker(line):
            # å‘ç° Tool ç»“æœå—èµ·å§‹
            result_lines.append(line)
            stats['kept_lines'] += 1
            stats['tool_blocks_processed'] += 1
            in_tool_result_block = True
            omitted_count = 0
        elif is_tool_call_start(line):
            # å‘ç° Assistant å·¥å…·è°ƒç”¨å—ï¼Œæ”¶é›† JSON å¹¶å¤„ç†
            # èµ·å§‹è¡Œæ ¼å¼: ğŸ› ï¸ tool_name (toolu_xxx) {
            # éœ€è¦æŠŠèµ·å§‹è¡Œçš„ { å’Œåç»­å†…å®¹åˆå¹¶æˆå®Œæ•´ JSON
            
            # æå–èµ·å§‹è¡Œä¸­ { ä¹‹å‰çš„éƒ¨åˆ†ä½œä¸ºæ ‡è¯†
            brace_pos = line.find('{')
            if brace_pos == -1:
                # æ²¡æœ‰ {ï¼ŒåŸæ ·ä¿ç•™
                result_lines.append(line)
                stats['kept_lines'] += 1
                i += 1
                continue
            
            header = line[:brace_pos].rstrip()  # ğŸ› ï¸ tool_name (toolu_xxx)
            i += 1
            
            # æ”¶é›† JSON å†…å®¹ç›´åˆ°æ‹¬å·å¹³è¡¡
            json_lines = ['{']  # ä»èµ·å§‹è¡Œå–çš„ {
            brace_depth = 1
            while i < len(lines) and brace_depth > 0:
                json_line = lines[i]
                json_lines.append(json_line.rstrip('\n'))
                brace_depth += json_line.count('{') - json_line.count('}')
                i += 1
            
            # å¤„ç†æ”¶é›†åˆ°çš„ JSON
            json_str = '\n'.join(json_lines)
            processed_json = process_tool_call_json(json_str, stats)
            
            # è¾“å‡º: æ ‡è¯†è¡Œ + å¤„ç†åçš„ JSON
            result_lines.append(header + ' ')
            result_lines.append(processed_json + '\n')
            stats['kept_lines'] += 2
            continue  # å·²ç»åœ¨å†…éƒ¨å¾ªç¯ä¸­å¤„ç†äº† i
        else:
            # æ™®é€šè¡Œï¼Œç›´æ¥ä¿ç•™
            result_lines.append(line)
            stats['kept_lines'] += 1
        
        i += 1
    
    # å¤„ç†æ–‡ä»¶æœ«å°¾æœªé—­åˆçš„æƒ…å†µ
    if in_tool_result_block and omitted_count > 0:
        result_lines.append(f'... ({omitted_count} lines omitted)\n')
        stats['kept_lines'] += 1
    
    return ''.join(result_lines), stats


def print_stats(stats: dict, input_path: str, output_path: str) -> None:
    """æ‰“å°å‹ç¼©ç»Ÿè®¡ä¿¡æ¯"""
    original = stats['original_lines']
    kept = stats['kept_lines']
    omitted = stats['omitted_lines']
    strings_truncated = stats.get('strings_truncated', 0)
    chars_saved = stats.get('chars_saved', 0)
    
    if original > 0:
        compression_ratio = (1 - kept / original) * 100
    else:
        compression_ratio = 0
    
    print("\nğŸ“Š å‹ç¼©ç»Ÿè®¡:")
    print(f"   è¾“å…¥æ–‡ä»¶: {input_path}")
    print(f"   è¾“å‡ºæ–‡ä»¶: {output_path}")
    print("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"   åŸå§‹è¡Œæ•°: {original:,}")
    print(f"   ä¿ç•™è¡Œæ•°: {kept:,}")
    print(f"   çœç•¥è¡Œæ•°: {omitted:,}")
    print(f"   å‹ç¼©æ¯”ä¾‹: {compression_ratio:.1f}%")
    print(f"   å¤„ç†çš„ Tool å—: {stats['tool_blocks_processed']}")
    if strings_truncated > 0:
        print(f"   æˆªæ–­çš„é•¿å­—ç¬¦ä¸²: {strings_truncated}")
        print(f"   èŠ‚çœçš„å­—ç¬¦æ•°: {chars_saved:,}")


def main():
    parser = argparse.ArgumentParser(
        description='ä» .copilotmd æ–‡ä»¶æå–éª¨æ¶ç»“æ„ï¼Œçœç•¥ Tool ç»“æœçš„å…·ä½“å†…å®¹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python copilotmd_skeleton.py chat.copilotmd
      -> è¾“å‡ºåˆ° chat.skeleton.copilotmd
  
  python copilotmd_skeleton.py chat.copilotmd -o summary.md
      -> è¾“å‡ºåˆ° summary.md
  
  python copilotmd_skeleton.py chat.copilotmd --stats
      -> è¾“å‡ºå¹¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        """
    )
    
    parser.add_argument(
        'input',
        type=str,
        help='è¾“å…¥çš„ .copilotmd æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '-o', '--output',
        type=str,
        default=None,
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: input.skeleton.copilotmdï¼‰'
    )
    
    parser.add_argument(
        '--stats',
        action='store_true',
        help='æ˜¾ç¤ºå‹ç¼©ç»Ÿè®¡ä¿¡æ¯'
    )
    
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}", file=sys.stderr)
        sys.exit(1)
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if args.output:
        output_path = Path(args.output)
    else:
        # é»˜è®¤: input.copilotmd -> input.skeleton.copilotmd
        stem = input_path.stem
        if stem.endswith('.copilot'):
            # å¤„ç† xxx.copilot.md çš„æƒ…å†µ
            stem = stem[:-7] + '.skeleton.copilot'
        else:
            stem = stem + '.skeleton'
        output_path = input_path.with_name(stem + input_path.suffix)
    
    # è¯»å–è¾“å…¥æ–‡ä»¶
    try:
        content = input_path.read_text(encoding='utf-8')
    except Exception as e:
        print(f"âŒ é”™è¯¯: æ— æ³•è¯»å–è¾“å…¥æ–‡ä»¶: {e}", file=sys.stderr)
        sys.exit(1)
    
    # æå–éª¨æ¶
    skeleton, stats = extract_skeleton(content)
    
    # å†™å…¥è¾“å‡ºæ–‡ä»¶
    try:
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(skeleton, encoding='utf-8')
        print(f"âœ… éª¨æ¶å·²ä¿å­˜åˆ°: {output_path}")
    except Exception as e:
        print(f"âŒ é”™è¯¯: æ— æ³•å†™å…¥è¾“å‡ºæ–‡ä»¶: {e}", file=sys.stderr)
        sys.exit(1)
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if args.stats:
        print_stats(stats, str(input_path), str(output_path))


if __name__ == '__main__':
    main()
